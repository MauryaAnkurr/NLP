{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"UK_Jobs.csv\",sep =\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"Guid\",\"Job_Text\",\"Title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.corpus import stopwords\n",
    "ENGLISH_STOP_WORDS = set([\n",
    "    'a',\n",
    "    'about',\n",
    "    'above',\n",
    "    'across',\n",
    "    'after',\n",
    "    'afterwards',\n",
    "    'again',\n",
    "    'against',\n",
    "    'ain',\n",
    "    'all',\n",
    "    'almost',\n",
    "    'alone',\n",
    "    'along',\n",
    "    'already',\n",
    "    'also',\n",
    "    'although',\n",
    "    'always',\n",
    "    'am',\n",
    "    'among',\n",
    "    'amongst',\n",
    "    'amoungst',\n",
    "    'amount',\n",
    "    'an',\n",
    "    'and',\n",
    "    'another',\n",
    "    'any',\n",
    "    'anyhow',\n",
    "    'anyone',\n",
    "    'anything',\n",
    "    'anyway',\n",
    "    'anywhere',\n",
    "    'are',\n",
    "    'aren',\n",
    "    'around',\n",
    "    'as',\n",
    "    'at',\n",
    "    'back',\n",
    "    'be',\n",
    "    'became',\n",
    "    'because',\n",
    "    'become',\n",
    "    'becomes',\n",
    "    'becoming',\n",
    "    'been',\n",
    "    'before',\n",
    "    'beforehand',\n",
    "    'behind',\n",
    "    'being',\n",
    "    'below',\n",
    "    'beside',\n",
    "    'besides',\n",
    "    'between',\n",
    "    'beyond',\n",
    "    'bill',\n",
    "    'both',\n",
    "    'bottom',\n",
    "    'but',\n",
    "    'by',\n",
    "    'call',\n",
    "    'can',\n",
    "    'cannot',\n",
    "    'cant',\n",
    "    'co',\n",
    "    'con',\n",
    "    'could',\n",
    "    'couldn',\n",
    "    'couldnt',\n",
    "    'cry',\n",
    "    'd',\n",
    "    'de',\n",
    "    'describe',\n",
    "    'detail',\n",
    "    'did',\n",
    "    'didn',\n",
    "    'do',\n",
    "    'does',\n",
    "    'doesn',\n",
    "    'doing',\n",
    "    'don',\n",
    "    'done',\n",
    "    'down',\n",
    "    'due',\n",
    "    'during',\n",
    "    'each',\n",
    "    'eg',\n",
    "    'eight',\n",
    "    'either',\n",
    "    'eleven',\n",
    "    'else',\n",
    "    'elsewhere',\n",
    "    'empty',\n",
    "    'enough',\n",
    "    'etc',\n",
    "    'even',\n",
    "    'ever',\n",
    "    'every',\n",
    "    'everyone',\n",
    "    'everything',\n",
    "    'everywhere',\n",
    "    'except',\n",
    "    'few',\n",
    "    'fifteen',\n",
    "    'fify',\n",
    "    'fill',\n",
    "    'find',\n",
    "    'fire',\n",
    "    'first',\n",
    "    'five',\n",
    "    'for',\n",
    "    'former',\n",
    "    'formerly',\n",
    "    'forty',\n",
    "    'found',\n",
    "    'four',\n",
    "    'from',\n",
    "    'front',\n",
    "    'full',\n",
    "    'further',\n",
    "    'get',\n",
    "    'give',\n",
    "    'go',\n",
    "    'had',\n",
    "    'hadn',\n",
    "    'has',\n",
    "    'hasn',\n",
    "    'hasnt',\n",
    "    'have',\n",
    "    'haven',\n",
    "    'having',\n",
    "    'he',\n",
    "    'hence',\n",
    "    'her',\n",
    "    'here',\n",
    "    'hereafter',\n",
    "    'hereby',\n",
    "    'herein',\n",
    "    'hereupon',\n",
    "    'hers',\n",
    "    'herself',\n",
    "    'him',\n",
    "    'himself',\n",
    "    'his',\n",
    "    'how',\n",
    "    'however',\n",
    "    'hundred',\n",
    "    'i',\n",
    "    'ie',\n",
    "    'if',\n",
    "    'in',\n",
    "    'inc',\n",
    "    'indeed',\n",
    "    'interest',\n",
    "    'into',\n",
    "    'is',\n",
    "    'isn',\n",
    "    'it',\n",
    "    'its',\n",
    "    'itself',\n",
    "    'just',\n",
    "    'keep',\n",
    "    'last',\n",
    "    'latter',\n",
    "    'latterly',\n",
    "    'least',\n",
    "    'less',\n",
    "    'll',\n",
    "    'ltd',\n",
    "    'm',\n",
    "    'ma',\n",
    "    'made',\n",
    "    'many',\n",
    "    'may',\n",
    "    'me',\n",
    "    'meanwhile',\n",
    "    'might',\n",
    "    'mightn',\n",
    "    'mill',\n",
    "    'mine',\n",
    "    'more',\n",
    "    'moreover',\n",
    "    'most',\n",
    "    'mostly',\n",
    "    'move',\n",
    "    'much',\n",
    "    'must',\n",
    "    'mustn',\n",
    "    'my',\n",
    "    'myself',\n",
    "    'name',\n",
    "    'namely',\n",
    "    'needn',\n",
    "    'neither',\n",
    "    'never',\n",
    "    'nevertheless',\n",
    "    'next',\n",
    "    'nine',\n",
    "    'no',\n",
    "    'nobody',\n",
    "    'none',\n",
    "    'noone',\n",
    "    'nor',\n",
    "    'not',\n",
    "    'nothing',\n",
    "    'now',\n",
    "    'nowhere',\n",
    "    'o',\n",
    "    'of',\n",
    "    'off',\n",
    "    'often',\n",
    "    'on',\n",
    "    'once',\n",
    "    'one',\n",
    "    'only',\n",
    "    'onto',\n",
    "    'or',\n",
    "    'other',\n",
    "    'others',\n",
    "    'otherwise',\n",
    "    'our',\n",
    "    'ours',\n",
    "    'ourselves',\n",
    "    'out',\n",
    "    'over',\n",
    "    'own',\n",
    "    'part',\n",
    "    'per',\n",
    "    'perhaps',\n",
    "    'please',\n",
    "    'put',\n",
    "    'rather',\n",
    "    're',\n",
    "    's',\n",
    "    'same',\n",
    "    'see',\n",
    "    'seem',\n",
    "    'seemed',\n",
    "    'seeming',\n",
    "    'seems',\n",
    "    'serious',\n",
    "    'several',\n",
    "    'shan',\n",
    "    'she',\n",
    "    'should',\n",
    "    'shouldn',\n",
    "    'show',\n",
    "    'side',\n",
    "    'since',\n",
    "    'sincere',\n",
    "    'six',\n",
    "    'sixty',\n",
    "    'so',\n",
    "    'some',\n",
    "    'somehow',\n",
    "    'someone',\n",
    "    'something',\n",
    "    'sometime',\n",
    "    'sometimes',\n",
    "    'somewhere',\n",
    "    'still',\n",
    "    'such',\n",
    "    'system',\n",
    "    't',\n",
    "    'take',\n",
    "    'ten',\n",
    "    'than',\n",
    "    'that',\n",
    "    'the',\n",
    "    'their',\n",
    "    'theirs',\n",
    "    'them',\n",
    "    'themselves',\n",
    "    'then',\n",
    "    'thence',\n",
    "    'there',\n",
    "    'thereafter',\n",
    "    'thereby',\n",
    "    'therefore',\n",
    "    'therein',\n",
    "    'thereupon',\n",
    "    'these',\n",
    "    'they',\n",
    "    'thick',\n",
    "    'thin',\n",
    "    'third',\n",
    "    'this',\n",
    "    'those',\n",
    "    'though',\n",
    "    'three',\n",
    "    'through',\n",
    "    'throughout',\n",
    "    'thru',\n",
    "    'thus',\n",
    "    'to',\n",
    "    'together',\n",
    "    'too',\n",
    "    'top',\n",
    "    'toward',\n",
    "    'towards',\n",
    "    'twelve',\n",
    "    'twenty',\n",
    "    'two',\n",
    "    'un',\n",
    "    'under',\n",
    "    'until',\n",
    "    'up',\n",
    "    'upon',\n",
    "    'us',\n",
    "    've',\n",
    "    'very',\n",
    "    'via',\n",
    "    'was',\n",
    "    'wasn',\n",
    "    'we',\n",
    "    'well',\n",
    "    'were',\n",
    "    'weren',\n",
    "    'what',\n",
    "    'whatever',\n",
    "    'when',\n",
    "    'whence',\n",
    "    'whenever',\n",
    "    'where',\n",
    "    'whereafter',\n",
    "    'whereas',\n",
    "    'whereby',\n",
    "    'wherein',\n",
    "    'whereupon',\n",
    "    'wherever',\n",
    "    'whether',\n",
    "    'which',\n",
    "    'while',\n",
    "    'whither',\n",
    "    'who',\n",
    "    'whoever',\n",
    "    'whole',\n",
    "    'whom',\n",
    "    'whose',\n",
    "    'why',\n",
    "    'will',\n",
    "    'with',\n",
    "    'within',\n",
    "    'without',\n",
    "    'won',\n",
    "    'would',\n",
    "    'wouldn',\n",
    "    'y',\n",
    "    'yet',\n",
    "    'you',\n",
    "    'your',\n",
    "    'yours',\n",
    "    'yourself',\n",
    "    'yourselves'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,3),use_idf=True,stop_words=ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(df[\"Job_Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x41249 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 773 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 41249)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lsa = TruncatedSVD(2,n_iter=100)\n",
    "lsa.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00217448, 0.00217448, 0.00217448, ..., 0.00171147, 0.00171147,\n",
       "       0.00171147])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa = TruncatedSVD(2,n_iter=100) \n",
    "lsa.fit(X)\n",
    "lsa.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concepts 0\n",
      "care\n",
      "support\n",
      "experience\n",
      "work\n",
      "role\n",
      "working\n",
      "school\n",
      "business\n",
      "team\n",
      "people\n",
      " \n",
      "concepts 1\n",
      "care\n",
      "school\n",
      "young\n",
      "teaching\n",
      "children\n",
      "young people\n",
      "assistant\n",
      "teaching assistant\n",
      "education\n",
      "vision\n",
      " \n"
     ]
    }
   ],
   "source": [
    "terms =vectorizer.get_feature_names()\n",
    "for i,comp in enumerate(lsa.components_):\n",
    "    termsincomp = zip(terms,comp)\n",
    "    sortedTerms = sorted(termsincomp,key=lambda x:x[1],reverse =True)[:10]\n",
    "    print(\"concepts\",i)\n",
    "    for term in sortedTerms:\n",
    "        print(term[0])\n",
    "    print(\" \")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
