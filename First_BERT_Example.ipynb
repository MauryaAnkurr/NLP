{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "First_BERT_Example.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7411ppCXOHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = \"maui-semeval2010-train\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeFyFXqKkgki",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "e0819dea-d1a8-4fa3-e005-b1f23bee303e"
      },
      "source": [
        "#import nltk\n",
        "#nltk.download('punkt')\n",
        "pip install pytorch-pretrained-bert"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.10.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.17.4)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.3.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.40 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.13.40)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.11.28)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.40->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.40->boto3->pytorch-pretrained-bert) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.40->boto3->pytorch-pretrained-bert) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xstxgGxqYEOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from nltk.tokenize import sent_tokenize\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvZAP-QOjz1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "txt = sorted([f for f in os.listdir(train_path) if not f.endswith(\"-justTitle.txt\") and not f.endswith(\".key\") and not f.endswith(\"-CrowdCountskey\")])\n",
        "key = sorted([f for f in os.listdir(train_path) if f.endswith(\".key\")])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_z1c0aEkj1Vj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filekey = dict()\n",
        "for i, k in enumerate(txt):\n",
        "    filekey[key[i]] = k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvIQ674Mj_zT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(key):\n",
        "    sentences = \"\"\n",
        "    for line in open(train_path + \"/\" + filekey[key], 'r'):\n",
        "        sentences += (\" \" + line.rstrip())\n",
        "    tokens = sent_tokenize(sentences)\n",
        "    key_file = open(train_path + \"/\" + str(key),'r')\n",
        "    keys = [line.strip() for line in key_file]\n",
        "    key_sent = []\n",
        "    labels = []\n",
        "    for token in tokens:\n",
        "        z = ['O'] * len(token.split())\n",
        "        for k in keys:\n",
        "            if k in token:\n",
        "                \n",
        "                if len(k.split())==1:\n",
        "                    try:\n",
        "                        z[token.lower().split().index(k.lower().split()[0])] = 'B'\n",
        "                    except ValueError:\n",
        "                        continue\n",
        "                elif len(k.split())>1:\n",
        "                    try:\n",
        "                        if token.lower().split().index(k.lower().split()[0]) and token.lower().split().index(k.lower().split()[-1]):\n",
        "                            z[token.lower().split().index(k.lower().split()[0])] = 'B'\n",
        "                            for j in range(1, len(k.split())):\n",
        "                                z[token.lower().split().index(k.lower().split()[j])] = 'I'\n",
        "                    except ValueError:\n",
        "                        continue\n",
        "        for m, n in enumerate(z):\n",
        "            if z[m] == 'I' and z[m-1] == 'O':\n",
        "                z[m] = 'O'\n",
        "\n",
        "        if set(z) != {'O'}:\n",
        "            labels.append(z) \n",
        "            key_sent.append(token)\n",
        "    return key_sent, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSogjhL4j_1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_ = []\n",
        "labels_ = []\n",
        "for key, value in filekey.items():\n",
        "    s, l = convert(key)\n",
        "    sentences_.append(s)\n",
        "    labels_.append(l)\n",
        "sentences = [item for sublist in sentences_ for item in sublist]\n",
        "labels = [item for sublist in labels_ for item in sublist]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DarkGg5Dj_46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertForTokenClassification, BertAdam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsSrKRuzj_-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG7JXkLzkABz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 75\n",
        "bs = 32\n",
        "tag2idx = {'B': 0, 'I': 1, 'O': 2}\n",
        "tags_vals = ['B', 'I', 'O']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlrLCZGRkAGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwO_tkw6kAJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbX4wguQmmYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7IVWjcMmmeH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "cab267b7-a384-4237-8486-6e05b2970576"
      },
      "source": [
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],maxlen=MAX_LEN, value=tag2idx[\"O\"], padding=\"post\", dtype=\"long\", truncating=\"post\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (766 > 512). Running this sequence through BERT will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (714 > 512). Running this sequence through BERT will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (544 > 512). Running this sequence through BERT will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (630 > 512). Running this sequence through BERT will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (1001 > 512). Running this sequence through BERT will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8OIsi6Ymmjk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_masks = [[float(i>0) for i in ii] for ii in input_ids]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPO_l3X6mmmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwwDx_8rmmpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_inputs = torch.tensor(tr_inputs)\n",
        "val_inputs = torch.tensor(val_inputs)\n",
        "tr_tags = torch.tensor(tr_tags)\n",
        "val_tags = torch.tensor(val_tags)\n",
        "tr_masks = torch.tensor(tr_masks)\n",
        "val_masks = torch.tensor(val_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3t5jYzJmmuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
        "\n",
        "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxN79v_jmmr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(tag2idx))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6RPctRQmmcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.cuda()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3EZzzzHm7Em",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FULL_FINETUNING = True\n",
        "if FULL_FINETUNING:\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "else:\n",
        "    param_optimizer = list(model.classifier.named_parameters()) \n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e62RfDi-m7I2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from seqeval.metrics import f1_score\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eBLLTASm7Pk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e035c9ed-f43f-484d-ebfb-f7af719931d5"
      },
      "source": [
        "epochs = 4\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "    # TRAIN loop\n",
        "    model.train()\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # add batch to gpu\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        # forward pass\n",
        "        loss = model(b_input_ids, token_type_ids=None,\n",
        "                     attention_mask=b_input_mask, labels=b_labels)\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        # track train loss\n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        model.zero_grad()\n",
        "    # print train loss per epoch\n",
        "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "    # VALIDATION on validation set\n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    predictions , true_labels = [], []\n",
        "    for batch in valid_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
        "                                  attention_mask=b_input_mask, labels=b_labels)\n",
        "            logits = model(b_input_ids, token_type_ids=None,\n",
        "                           attention_mask=b_input_mask)\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "        true_labels.append(label_ids)\n",
        "        \n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        eval_loss += tmp_eval_loss.mean().item()\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        \n",
        "        nb_eval_examples += b_input_ids.size(0)\n",
        "        nb_eval_steps += 1\n",
        "    eval_loss = eval_loss/nb_eval_steps\n",
        "    print(\"Validation loss: {}\".format(eval_loss))\n",
        "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "    pred_tags = [tags_vals[p_i] for p in predictions for p_i in p]\n",
        "    valid_tags = [tags_vals[l_ii] for l in true_labels for l_i in l for l_ii in l_i]\n",
        "    print(\"F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdQ1GTUnm7St",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "predictions = []\n",
        "true_labels = []\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "for batch in valid_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
        "                              attention_mask=b_input_mask, labels=b_labels)\n",
        "        logits = model(b_input_ids, token_type_ids=None,\n",
        "                       attention_mask=b_input_mask)\n",
        "        \n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    true_labels.append(label_ids)\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "    eval_loss += tmp_eval_loss.mean().item()\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    nb_eval_examples += b_input_ids.size(0)\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "pred_tags = [[tags_vals[p_i] for p_i in p] for p in predictions]\n",
        "valid_tags = [[tags_vals[l_ii] for l_ii in l_i] for l in true_labels for l_i in l ]\n",
        "print(\"Validation loss: {}\".format(eval_loss/nb_eval_steps))\n",
        "print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "print(\"Validation F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VS4zllOm7YU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def keywordextract(sentence):\n",
        "    text = sentence\n",
        "    tkns = tokenizer.tokenize(text)\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tkns)\n",
        "    segments_ids = [0] * len(tkns)\n",
        "    tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
        "    segments_tensors = torch.tensor([segments_ids]).to(device)\n",
        "    model.eval()\n",
        "    prediction = []\n",
        "    logit = model(tokens_tensor, token_type_ids=None,\n",
        "                                  attention_mask=segments_tensors)\n",
        "    logit = logit.detach().cpu().numpy()\n",
        "    prediction.extend([list(p) for p in np.argmax(logit, axis=2)])\n",
        "    for k, j in enumerate(prediction[0]):\n",
        "        if j==1 or j==0:\n",
        "            print(tokenizer.convert_ids_to_tokens(tokens_tensor[0].to('cpu').numpy())[k], j)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oovWyzaim7V5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"Overview\\n  \\nMister Car Wash is rewriting the rules of the car wash industry.\\n  \\nWe wash cars for the fun of it. We put our people first. We help turn jobs into careers.\\n  \\nSound good? Come work for us! We're currently seeking a Manager\\n  \\nWHAT MOTIVATES OUR TEAM:\\n\\n* Monthly bonus potential based on performance\\n* Advancement opportunities across the country\\n* Free car washes\\n* Generous paid time off that increases with tenure\\n* Industry-leading benefits, including medical, dental, vision, and tuition reimbursement\\n* Ongoing training and development\\n* Fun, inclusive, and positive working environment\\n* Tuition reimbursement for GED, college classes, trade certifications, and ESL classes \\n  \\nHOW YOU WILL SHINE:\\n\\n* Adapt your prior experience to the car wash industry through our management curriculum and mentorship under a General Manager\\n* Lead a team to deliver an outstanding customer experience\\n* Grow customer volume, driving sales and increasing profitability for the store\\n* Coach staff to create a positive, high-energy environment that customers can feel\\n* Train and support staff at varying levels of development\\n* Manage daily operations, deliver consistent high-quality services, and promote Mister Car Wash within your community\\n* Keep your location neat, clean, and appealing to customers\\n  \\nMANAGERS SHOWCASE:\\n\\n* A track record of successful outcomes and a willingness to take ownership\\n* Experience with labor management and strategic staff scheduling\\n* Demonstrated leadership and team-building skills\\n* A desire to learn mechanical and electrical skillsets\\n* A high level of initiative, attention to detail, and pride in a job well done\\n* Working knowledge of Microsoft Office Suite (Word, Excel, and Outlook)\\n* The ability to multitask in a rapidly changing environment\\n* A passion for building relationships with customers and community members\\n* Availability to work long hours, including weekends, with a varying schedule\\n* A desire to be active and outdoors in varying temperatures and weather conditions\\n* Upon offer, selected candidates are required to complete a pre-hire background check and driving history review.\\n  \\nNo previous car wash experience is necessary. You bring the energy and skills—we'll teach you the rest!\\n  \\nIt's your time to SHINE! Join the Mister Car Wash Team today!\\n  \\ncareers.mistercarwash.com\\n  \\nMister Car Wash provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, or genetics. We participate in the E-verify system nationwide.\\n\\n\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMDpqVxfng6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(keywordextract(text))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}